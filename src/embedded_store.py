import hashlib
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

def generate_doc_id(file_path):
    """Táº¡o doc_id duy nháº¥t dá»±a trÃªn ná»™i dung file."""
    with open(file_path, "rb") as f:
        data = f.read()
    return hashlib.md5(data).hexdigest()

def create_or_update_vector_db(chunks, file_path, persist_dir="vectorstore"):
    """Upsert vectorstore cho 1 file PDF."""
    doc_id = generate_doc_id(file_path)

    # Gáº¯n doc_id vÃ o metadata cá»§a tá»«ng chunk
    for c in chunks:
        c.metadata["doc_id"] = doc_id
        c.metadata["source_file"] = file_path  # tiá»‡n Ä‘á»ƒ trace

    vectordb = Chroma(persist_directory=persist_dir, embedding_function=embeddings)

    # Náº¿u doc_id Ä‘Ã£ tá»“n táº¡i â†’ xoÃ¡ trÆ°á»›c
    existing_ids = [f"{doc_id}_{i}" for i in range(10_000)]  # sá»‘ Ä‘á»§ lá»›n
    vectordb.delete(ids=existing_ids)
    print(f"ğŸ—‘ï¸  Deleted old chunks for doc {file_path} (doc_id={doc_id})")

    # Add chunks má»›i
    vectordb.add_documents(chunks)
    print(f"âœ… Upserted {len(chunks)} chunks for doc {file_path}")
    return vectordb


def load_vector_db(persist_dir="vectorstore"):
    """Load láº¡i vector DB Ä‘Ã£ lÆ°u."""
    vectordb = Chroma(persist_directory=persist_dir, embedding_function=embeddings)
    return vectordb